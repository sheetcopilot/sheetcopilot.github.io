
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models</title>

    <meta name="description" content="SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- <base href="/"> -->

        <!--FACEBOOK-->
    <meta property="og:image" content="https://sheetcopilot.github.io/img/SheetCopilot-teaser.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1262">
    <meta property="og:image:height" content="694">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://sheetcopilot.github.io/"/>
    <meta property="og:title" content="SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models" />
    <meta property="og:description" content="Project page for SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models." />

        <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models" />
    <meta name="twitter:description" content="Project page for SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models." />
    <meta name="twitter:image" content="https://palm-e.github.io/img/SheetCopilot-teaser.png" />


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <!-- <link rel="icon" type="image/png" href="img/seal_icon.png"> -->
    <!-- Place favicon.ico in the root directory -->
    <link rel="icon" type="image/x-icon" href="img/icon.png">

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script>

        timeoutIds = [];
        
        function populateDemo(imgs) {
            // Get the expanded image
            var expandImg = document.getElementById("expandedImg");
            // Get the image text
            var imgText = document.getElementById("imgtext");
            var answer = document.getElementById("answer");
        
            // Use the same src in the expanded image as the image being clicked on from the grid
            expandImg.src = imgs.src;
            // Use the value of the alt attribute of the clickable image as text inside the expanded image
            var qa = imgs.alt.split("[sep]");
            imgText.innerHTML = qa[0];
            answer.innerHTML = "";
            // Show the container element (hidden with CSS)
            expandImg.parentElement.style.display = "block";
            for (timeoutId of timeoutIds) {
                clearTimeout(timeoutId);
            }
            typeWriter(qa[1], 0, qa[0]);
            }
        
        function typeWriter(txt, i, q) {
            var imgText = document.getElementById("imgtext");
            if (imgText.innerHTML == q) {
            if (i < txt.length) {
                document.getElementById("answer").innerHTML += txt.charAt(i);
                i++;
                timeoutIds.push(setTimeout(typeWriter, 20, txt, i, q));
            }
            }
        }

        </script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-52J0PM8XKV"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-52J0PM8XKV');
</script>
	
    <style>
        .nav-pills {
          position: relative;
          display: inline;
        }
        .imtip {
          position: absolute;
          top: 0;
          left: 0;
        }
    </style>
</head>

<body>
    <div class="container" id="main">
        
        <div class="row">
            <p></p> <p></p>
            <div class="col-md-12 text-center">
                <strong><font size="+3">SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models</font></strong> 
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                
                <ul class="list-inline">
                    <br>
                    <li>Anonymous</li>
                    <br><br>
                    <!-- Institutes -->
                    <!-- <sup>1</sup><a href="http://g.co/robotics">
                        <img src="img/rng-logo.png" height="37px"> </a>
                        <sup>2</sup><a href="https://www.tu.berlin/en/">
                        <img src="img/tuberlin.png" height="32px"> </a> &nbsp;&nbsp;
                        <sup>3</sup><a href="https://research.google/teams/brain/">  
                        <img src="img/google-research-logo.png" height="25px"> </a>  -->
                        
                    </ul>

            </div>
        </div>


        <div class="row">
            <div class="col-md-4 col-md-offset-4 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="assets/palm-e.pdf">
                        <img src="img/paper_thumb.png" height="60px">
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>

                    <li>
                        <a href="#demo">
                        <img src="img/SheetCopilot-teaser.png" height="60px">
                            <h4><strong>Demo</strong></h4>
                        </a>
                    </li> 
<!--                         <li>
                        <a href="http://ai.googleblog.com/2022/12/rt-1-robotics-transformer-for-real.html">
                        <image src="img/google-ai-blog-small.png" height="60px">
                            <h4><strong>Blogpost</strong></h4>
                        </a>
                    </li>
                     <li>
                        <a href="https://github.com/google-research/robotics_transformer">
                        <image src="img/github.png" height="60px">
                            <h4><strong>Code</strong></h4>
                        </a>                   
                    </li>  -->
                </ul>
            </div>
        </div>

        <div class="row">
            
            <div class="col-md-8 col-md-offset-2 col-xs-12">
                <video id="v0" width="100%" playsinline muted loop autoplay onclick="setAttribute('controls', 'true');">
                    <source src="videos/SheetCopilot-teaser.mp4" type="video/mp4">
                </video>		

                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Computer end users have spent billions of hours completing daily tasks like tabular data processing and project timeline scheduling. Most of these tasks are repetitive and error-prone, yet most end users lack the skill of automating away these burdensome works. With the advent of large language models (LLMs), directing software with natural language user requests become a reachable goal.
                    In this work, we propose a SheetCopilot agent which takes natural language task and control spreadsheet to fulfill the requirements. We propose a set of atomic actions as an abstraction of spreadsheet software functionalities. We further design a state machine-based task planning framework for LLMs to robustly interact with spreadsheets. We curate a representative dataset containing 221 spreadsheet control tasks and establish a fully automated evaluation pipeline for rigorously benchmarking the ability of LLMs in software control tasks. Our SheetCopilot correctly completes 44.3% of tasks for a single generation, outperforming the strong code generation baseline by a wide margin.
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2 col-xs-12">
                <h3>
                    Method
                </h3>
                
                <!-- Mehtod Overview-->
                <h4>
                    Overview
                </h4>
                <p style="text-align:center;">
                    <img src="img/approach.png" class="img-responsive">
                </p>

                <p class="text-justify">
                  We maneuver the proposed SheetCopilot for controlling software such as Microsoft Excel to generate solutions fulfilling the user's requirements in the instruction. SheetCopilot plans an initial atomic action according to the sheet state and then revises this plan using the external document containing the action usage. Finally, the action with its arguments is extracted from the revised plan and submitted to the simulation environment for execution. The entire process on the right shows that SheetCopilot successfully solves the task specified in the instruction using the provided available atomic actions.
                </p>    

                <p><br></p>

                <!-- State Machine -->
                <h4>
                    SheetCopilot State Machine
                </h4>

                <p style="text-align:center;">
                    <img src="img/state_machine.png" class="img-responsive">
                </p>
                
                <p class="text-justify">
                    SheetCopilot utilizes a state machine-based planner which revises the plan according to feedback from either LMs or software. Our planner is divided into <b>observing</b>, <b>proposing</b>, <b>revising</b>, and <b>acting</b> stages. The state transition between these stages will be described below.
                    <ul  class="text-justify">
                        <li><b>Observing Stage.</b> A brief description of the sheet state is added to the query, providing information such as the column headers and the number of rows. This helps to generate solutions in a <b>closed-loop</b> manner by observing the previous actions' consequences.</li>
                        <li><b>Proposing Stage.</b> The system prompt, task instruction, sheet state, and planning history are concatenated into one complete query, which is used to prompt the language model (e.g. GPT-3.5) to plan the next atomic action</li>
                        <li><b>Revising Stage.</b> Two ways are adopted to revise a proposed atomic action: a feedback-based one and a retrieval-based one. <i>Feedback-based revision</i> utilizes the error feedback from both the action validation process and the spreadsheet software execution. Additionally, we use <i>Retrieval-based revision</i> to supply the model with detailed external knowledge that does not fit in the system prompt due to the context window limit.</li>
                        <li><b>Acting Stage.</b> After the proposing and revising stages, the atomic action is submitted to the spreadsheet software for execution.</li>
                    </ul>
                    In the above diagram, the transfer condition (orange texts within brackets) must be fulfilled before performing the corresponding operation (green texts) to transfer to a next state.
                    

                </p>    

                
            </div>
        </div>



        <div class="row" id="dataset">
            <div class="col-md-8 col-md-offset-2 col-xs-12">
                <h3>
                    Dataset
                </h3>
                <p class="text-justify">
                    We construct <a href="https://paperswithcode.com/dataset/sheetcopilot">a high-quality evaluation benchmark</a> as a foundation for assessing the spreadsheet control capabilities of various methods interested in this field, such as LLM-based methods and reinforcement learning-based methods.<br>
                    The SheetCopilot dataset contains 28 evaluation workbooks and 221 spreadsheet manipulation tasks that are applied to these workbooks. These tasks involve diverse atomic actions related to the six task categories (i.e. Entry and manipulation, Formatting, Management, Charts, Pivot Table, and Formula).<br>
                    <b>Dataset statistics:</b><br>
                    1. Each task possesses one or more ground truth solutions.<br>
                    2. The lengths of the task instructions range from 20 to 530 characters, with most tasks between 80 and 110 characters.<br>
                    3. The numbers of atomic actions required by the tasks range from 1 to 9.<br>
                    <b>Evaluation metrics:</b>
                    <ul class="text-justify">
                        <li><b>Exec@1</b> measures the proportion of solutions executed without throwing exceptions.</li>
                        <li><b>Pass@1</b> is used to evaluate functional correctness.</li>
                        <li>Beyond correctness, we propose <b>A50</b> and <b>A90</b> scores to measure solution efficiency. These two metrics divide the number of atomic actions in a generated plan by the number in the ground truth and then calculate the 50th and 90th percentiles over all tasks. (Lower A50 and A90 scores indicate that the LLM tends to use fewer actions for completing a task.)</li>
                    </ul>
                    
                    A submitted solution is considered correct if the properties to be checked match those of any of the GT solutions of the corresponding task.<br>
                </p>
                <p><br></p>

                <!-- Dataset word clouds -->
                <p style="text-align:center;">
                    <img src="img/dataset_img/two_clouds.png" width="100%" alt="SheetCopilot example: Handling sales data.">
                </p>
                        
                <p class="text-justify">
                    <b>Dataset overview.</b> An overview of our dataset in shown by the wordclouds of the instructions and involved atomic actions. The two clouds show that our dataset contains diverse tasks that involve various spreadsheet operations.
                </p>
                <p><br></p>

                <!-- Cate proportions and donut chart -->
                <p style="text-align:center;">
                    <img src="img/dataset_img/CatePropAndVerbNoun.png" width="100%" alt="SheetCopilot example: Handling sales data.">
                </p>
                        
                <p class="text-justify">
                    Left: The proportions of the six categories. Right: Diversity of the verb-noun phrases in the core set. We demonstrate the diversity of the core set by showing the top 10 most frequent root verbs (the inner circle) and their direct noun objects (the outer circle) in the instructions.
                </p>
                <p><br></p>

                <!-- Histograms -->
                <p style="text-align:center;">
                    <img src="img/dataset_img/Instruc&ActDistributions.png" width="100%" alt="SheetCopilot example: Handling sales data.">
                </p>
                        
                <p class="text-justify">
                    <b>Dataset statistics.</b> The distributions of the instruction lengths and the numbers of atomic actions involved in each instruction. The two histograms demonstrate the diverse task complexity of the core set.
                </p>
                <p><br></p>

                
            </div>
        </div>
        
        <div class="row" id="demo">
            <div class="col-md-8 col-md-offset-2 col-xs-12">
                <h3>
                    Demo
                </h3>
                <p class="text-justify">
                  SheetCopilot example: Handling sales data. The left column shows that SheetCopilot generates a step-by-step solution according to the sheet state feedback and correctly revises its mistakes using the external atomic action document as well as the error feedback. The incorrect arguments are marked with red rectangles. The right column demonstrates the state changes of the evaluation sheet corresponding to each step on the left. For illustration clarity, only brief documents are displayed.
                </p>
                
                <img src="img/SalesData_demo.png" width="100%" alt="SheetCopilot example: Handling sales data.">
                <p></p>

            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2 col-xs-12">
                <h3>
                    Results
                </h3>

                <!-- LLM comparison -->
                <p style="text-align:center;">
                    <img src="img/exp_img/LLM_comparison.png" class="img-responsive" width="60%">
                </p>

                <p class="text-justify">
                    <b>Exp. 1.1: Performances of three leading LLMs and a VBA-based method.</b> The three LLMs exhibit impressive Exec@1 and Pass@1, with GPT-3.5-Turbo achieving the highest Exec@1 and GPT-4 obtaining the best Pass@1 and efficiency. With our method, GPT-3.5-Turbo outperforms the method that generates and runs VBA code by a large margin.
                </p>
                <p><br></p>

                <!-- Radar charts -->
                <p style="text-align:center;">
                    <img src="img/exp_img/RadarCharts.png" class="img-responsive">
                </p>

                <p class="text-justify">
                    <b>Exp 1.2: The four metrics shown in the above table are decomposed in the six task categories.</b> The two GPT models both achieve 100% Exec@1 and Pass@1 in the Management and Entry \& manipulation categories. The three models obtain their own best efficiency in different categories, suggesting that it is difficult for these models to excel in all task categories.
                </p> 
                <p><br></p>

                <!-- Ablation studies -->
                <p style="text-align:center;">
                    <img src="img/exp_img/ablation_studies.png" class="img-responsive">
                </p>

                <p class="text-justify">
                    <b>Exp 2: Ablation studies of the proposed observe-propose-revise-act framework used by our SheetCopilot.</b> The sheet state and error feedback increase the Exec@1 and Pass@1 when individually applied (rows 3, 4 vs. 2) and bring a significant improvement when both are applied (row 7 vs. 2). Inserting the external atomic action document with usage examples boosts the Exec@1 and Pass@1 and increases efficiency (row 2 vs. 1 and row 7 vs. 5). The synergy of the four components witnesses a large increase (30.7%) in Exec@1 over the baseline (row 7 vs. 1).
                </p> 
                <p><br></p>

                <!-- Synonyms -->
                <p style="text-align:center;">
                    <img src="img/exp_img/synonyms.png" class="img-responsive" width="60%">
                </p>

                <p class="text-justify">
                    <b>Exp 3: Ablation study of the atomic action names.</b> To inspect the potential confusion problem, we conduct an ablation study for GPT-3.5-Turbo on the full dataset by comparing the impact of adopting the official names and the synonyms. The table above <b>surprisingly</b> shows that using the synonyms increases the Pass@1 and obtains higher efficiency (lower A50/A90), which means that the model learns to use the synonyms to generate more correct solutions with fewer steps. <b>This result demonstrates the flexibility of our method: it is possible for users to define their own atomic actions and prompt LLMs to use them. </b>
                </p> 
                <p><br></p>

                <!-- Stability -->
                <p style="text-align:center;">
                    <img src="img/exp_img/stability.png" class="img-responsive" width="60%">
                </p>

                <p class="text-justify">
                    <b>Exp 4: Ablation study of the atomic action names.</b> We evaluate the stability of our method by running the full method three times at temperature=0.2 and calculate the averages for the four metrics. The table above shows that the metrics are stable with slight deviations from the metric values when temperature=0.0.
                </p> 
                <p><br></p>

            </div>
        </div>





    </div>
    <script>
    const myCarousel = document.getElementById('carouselExampleCaptions')
    myCarousel.addEventListener('slide.bs.carousel', event => {
        myCarousel.getElementsByClassName("carousel-item")[event.from].getElementsByTagName("video")[0].pause();
        myCarousel.getElementsByClassName("carousel-item")[event.to].getElementsByTagName("video")[0].play();
    })

    const myCarousel2 = document.getElementById('carouselExampleCaptions2')
    myCarousel2.addEventListener('slide.bs.carousel', event => {
        myCarousel2.getElementsByClassName("carousel-item")[event.from].getElementsByTagName("video")[0].pause();
        myCarousel2.getElementsByClassName("carousel-item")[event.to].getElementsByTagName("video")[0].play();
    })

    const myCarousel3 = document.getElementById('carouselExampleCaptions3')
    myCarousel3.addEventListener('slide.bs.carousel', event => {
        myCarousel3.getElementsByClassName("carousel-item")[event.from].getElementsByTagName("video")[0].pause();
        myCarousel3.getElementsByClassName("carousel-item")[event.to].getElementsByTagName("video")[0].play();
    })

    </script>
</body>
</html>
